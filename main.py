import requests
from bs4 import BeautifulSoup
import time
import os
import json
import hashlib
import telegram_sender

# ==========================================
# ê²Œì‹œíŒ ì„¤ì •
POST_LIMIT = 15
BOARDS = [
    {
        "name": "ğŸ“¢ í•™ë¶€ ê³µì§€",
        "url": "https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1",
        "file": "notice_list_v2.json"
    },
    {
        "name": "ğŸ’¼ í•™ë¶€ ì¸ì¬ ëª¨ì§‘",
        "url": "https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_3_a",
        "file": "recruit_list_v2.json"
    }
]
# ==========================================

def get_post_content(link):
    """
    ê²Œì‹œê¸€ ë³¸ë¬¸(ìƒì„¸ ë‚´ìš©)ì„ ê°€ì ¸ì™€ì„œ í•´ì‹œê°’(ì§€ë¬¸)ìœ¼ë¡œ
    """
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(link, headers=headers, timeout=5)
        if response.status_code != 200:
            return ""
        
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.select_one("#bo_v_con")
        
        if content_div:
            return content_div.get_text(strip=True)
        return ""
    except:
        return ""

def get_recent_posts(url, limit):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            return []
        
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        posts = []
        rows = soup.select("table tbody tr")
        
        for row in rows:
            if len(posts) >= limit:
                break 

            subject_tag = None
            for a_tag in row.select("a"):
                href = (a_tag.get("href") or "").strip()
                if "wr_id=" in href:
                    subject_tag = a_tag
                    break
            
            if not subject_tag: continue

            title = subject_tag.get_text(strip=True)
            link = (subject_tag.get("href") or "").strip()
            
            if not link.startswith("http"):
                link = "https://cse.knu.ac.kr/bbs/" + link.lstrip("./")

            try:
                post_id = link.split("wr_id=")[1].split("&")[0]
            except:
                post_id = link 

            date_tag = row.select_one(".td_datetime")
            post_date = date_tag.get_text(strip=True) if date_tag else "no-date"

            # ë³¸ë¬¸ ë‚´ìš© í™•ì¸ (í•´ì‹œê°’ ìƒì„±)
            content_text = get_post_content(link)
            content_hash = hashlib.md5(content_text.encode('utf-8')).hexdigest()

            posts.append({
                "id": post_id,
                "title": title,
                "date": post_date,
                "link": link,
                "content_hash": content_hash
            })
            time.sleep(0.3) # ì„œë²„ ë¶€í•˜ ë°©ì§€

        return posts

    except Exception as e:
        print(f"âŒ ëª©ë¡ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return []

def check_new_notice():
    print(f"\n[í…”ë ˆê·¸ë¨] ê°ì‹œ ì‹œì‘ ({time.strftime('%H:%M:%S')})")
    
    for board in BOARDS:
        board_name = board["name"]
        url = board["url"]
        filename = board["file"]
        
        current_posts = get_recent_posts(url, limit=POST_LIMIT)
        if not current_posts: continue

        saved_posts = {}
        if os.path.exists(filename):
            try:
                with open(filename, "r", encoding="utf-8") as f:
                    saved_posts = json.load(f)
            except:
                saved_posts = {}

        # ì²« ì‹¤í–‰ì´ë©´ ì €ì¥ë§Œ í•˜ê³  íŒ¨ìŠ¤
        if len(saved_posts) == 0:
            print(f"   {board_name}: ì²« ì‹¤í–‰! ê¸°ì¤€ì  ì €ì¥ ì™„ë£Œ.")
            new_save_data = {}
            for post in current_posts:
                new_save_data[post["id"]] = post
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(new_save_data, f, ensure_ascii=False, indent=4)
            continue

        # ì•Œë¦¼ ë³´ë‚¼ ë©”ì‹œì§€ë“¤ì„ ë‹´ì„ 'ìš°ì²´í†µ' (ë¦¬ìŠ¤íŠ¸)
        messages_queue = []
        changes_detected = False
        new_save_data = saved_posts.copy()

        for post in current_posts:
            pid = post["id"]
            title = post["title"]
            
            # (A) ìƒˆ ê¸€ ë°œê²¬
            if pid not in saved_posts:
                print(f"   ğŸ”¥ {board_name}: ìƒˆ ê¸€ -> {title}")
                msg = f"[{board_name} - âœ¨ ìƒˆ ê¸€]\n{title}"
                # ìš°ì²´í†µì— 'ë©”ì‹œì§€ ë‚´ìš©'ê³¼ 'ë§í¬'ë¥¼ ë‹´ìŒ
                messages_queue.append({"msg": msg, "link": post["link"]})
                
                new_save_data[pid] = post
                changes_detected = True

            # (B) ê¸°ì¡´ ê¸€ ìˆ˜ì • ë°œê²¬
            else:
                old_post = saved_posts[pid]
                old_hash = old_post.get("content_hash", "")
                
                is_header_changed = (old_post["title"] != title) or (old_post["date"] != post["date"])
                is_content_changed = (old_hash != post["content_hash"]) and (old_hash != "")

                if is_header_changed:
                    status = "ğŸ“ ì œëª©/ë‚ ì§œ ìˆ˜ì •ë¨"
                elif is_content_changed:
                    status = "ğŸ•µï¸ ë³¸ë¬¸ ë‚´ìš© ìˆ˜ì •ë¨"
                else:
                    status = None

                if status:
                    print(f"   â™»ï¸ {board_name}: {status} -> {title}")
                    msg = f"[{board_name} - {status}]\n{title}\n(ë§í¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”)"
                    messages_queue.append({"msg": msg, "link": post["link"]})
                    
                    new_save_data[pid] = post
                    changes_detected = True

        # ì—¬ëŸ¬ ê°œê°€ ë™ì‹œì— ì˜¬ë¼ì™”ì„ ë•Œ, 'ì˜¤ë˜ëœ ìˆœì„œ'ëŒ€ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ë’¤ì§‘ìŒ
        # ì±„íŒ…ë°©ì€ [ê³¼ê±°]ê°€ ìœ„ì— ìˆì–´ì•¼ ë³´ê¸°ê°€ í¸í•¨
        if messages_queue:
            print(f"   ì´ {len(messages_queue)}ê°œì˜ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.")
            
            # ë¦¬ìŠ¤íŠ¸ ë’¤ì§‘ê¸° (Newest First -> Oldest First)
            messages_queue.reverse()

            for item in messages_queue:
                try:
                    telegram_sender.send_msg(item["msg"], item["link"])
                    time.sleep(1)
                except Exception as e:
                    print(f"   ì „ì†¡ ì‹¤íŒ¨: {e}")


        if changes_detected:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(new_save_data, f, ensure_ascii=False, indent=4)
        else:
            print(f"    {board_name}: ë³€ë™ ì—†ìŒ")

if __name__ == "__main__":
    check_new_notice()
